{% include "scheduler/ai.sh.in" %}
{% include "runtime.sh.in" %}
{% bind_user_share_folder as job_user_share_folder %}
{% settings as settings %}
module try-load singularity
echo job start time is `date`
{%if distributed%}
export LICO_AVAILABLE_PORTS=@@{lico_port1_{% sum_items ps_worker|get_item:"psNumber"|default_if_none:2 ps_worker|get_item:"workerNumber"|default:2 %}}

ps_num={{ ps_worker|get_item:"psNumber"|default_if_none:2 }}
worker_num={{ ps_worker|get_item:"workerNumber"|default:2 }}
lico_ports_array=(`echo $LICO_AVAILABLE_PORTS | tr ','  ' '`)
{% get_exec_node settings.LICO.SCHEDULER 1 %}
port_index=0

function get_ps_worker_hosts(){
    num=$1
    ret=''
    while(( $num>0 ))
    do
        for exec_node in ${exec_nodes[*]}
        do
            if [ $num == 0 ]
            then
                break
            fi
            if [ ${#ret} -gt 0 ]
            then
                ret="${ret},${exec_node}:${lico_ports_array[$port_index]}"
            else
                ret="${exec_node}:${lico_ports_array[$port_index]}"
            fi
            let "port_index++"
            let "num--"
        done
    done
}

get_ps_worker_hosts $ps_num
ps_hosts=$ret

get_ps_worker_hosts $worker_num
worker_hosts=$ret

echo "ps:$ps_hosts  worker:$worker_hosts"

function run_ps_worker(){
    num=$1
    flag=$2
    i=0
    start_gpu=0
    while(( $num>0 ))
    do
        for exec_node in ${exec_nodes[*]}
        do
            if [ $num == 0 ]
            then
                break
            fi
            if [ $flag == "ps" ]
            then
                set -x
                {% scheduler_exec settings.LICO.SCHEDULER 0 gpu_per_node 0 %}$exec_node \
                    bash -c "export CUDA_VISIBLE_DEVICES=-1 && \
                    singularity exec {% if gpu_per_node %}--nv{% endif %} \
                    -B {{ lico.user.workspace|addslashes }} {{ job_user_share_folder|addslashes }} \
                    --pwd {{ job_workspace }} \
                    {{ image_path }} {% program_exec prog %} \
                    {%if ps_worker|get_item:"psNumber"%}--ps_hosts=$ps_hosts{%endif%} --worker_hosts=$worker_hosts --job_name=ps --task_index=$i {{ args|default:""|addslashes }}" &
                set +x
            else
                set -x
                {% scheduler_exec settings.LICO.SCHEDULER ps_worker|get_item:"gpuPerWorker" gpu_per_node 0 %}$exec_node \
                    bash -c "{% if gpu_per_node > 1 %}array=(\${CUDA_VISIBLE_DEVICES//,/ });devs=\$(printf ,%s \${array[@]:$start_gpu:{{ ps_worker|get_item:"gpuPerWorker" }} });CUDA_VISIBLE_DEVICES=\${devs:1} && {% endif %} \
                    singularity exec {% if gpu_per_node %}--nv{% endif %} \
                    -B {{ lico.user.workspace|addslashes }} {{ job_user_share_folder|addslashes }} \
                    --pwd {{ job_workspace }} \
                    {{ image_path }} {% program_exec prog %} \
                    {%if ps_worker|get_item:"psNumber"%}--ps_hosts=$ps_hosts{%endif%} --worker_hosts=$worker_hosts --job_name=worker --task_index=$i {{ args|default:""|addslashes }}" &
                set +x
            fi
            let "num--"
            let "i++"
        done
        start_gpu=$(( $start_gpu + {{ ps_worker|get_item:"gpuPerWorker" }} ))
    done
}

run_ps_worker $ps_num 'ps'
run_ps_worker $worker_num 'worker'

{% if ps_worker|get_item:"psNumber"|default_if_none:2 %}
# Wait for worker execution to complete
while true
do
    worker_num=`ps -ef | grep "ps_hosts=$ps_hosts --worker_hosts=$worker_hosts --job_name=worker" | wc -l`
    if [ $worker_num -eq 1 ]
    then
        break
    else
        sleep 1
    fi
done

{% if settings.LICO.SCHEDULER == "lsf" %}
for exec_node in ${exec_nodes[*]}
do
    {% scheduler_exec settings.LICO.SCHEDULER 0 gpu_per_node 0 %}$exec_node \
        bash -c "ps -ef | grep $ps_hosts | grep -v grep | awk '{print \$2}' | xargs kill -9"
done
{% endif %}
{% else %}
wait
{% endif %}

{%else%}
{% get_exec_node settings.LICO.SCHEDULER 0 %}
set -x
{% scheduler_exec settings.LICO.SCHEDULER gpu_per_node gpu_per_node|default:0 1 %}${exec_node} \{% if settings.LICO.SCHEDULER == "slurm" %}
    --cpus-per-task=${cpu_curr_node} \{% endif %}
    singularity exec {% if gpu_per_node %}--nv{% endif %} \
    -B {{ lico.user.workspace|addslashes }} {{ job_user_share_folder|addslashes }} \
    --pwd {{ job_workspace }} \
    {{ image_path }} {% program_exec prog %} {{ args|default:""|addslashes }}
set +x
{%endif%}
echo job end time is `date`
